import streamlit as st
import sys
import os
import base64
from io import BytesIO
from PIL import Image
import importlib

# Add agent directory to path and reload module each run so latest code is used
agent_dir = os.path.join(os.path.dirname(__file__), '..', 'agent')
if agent_dir not in sys.path:
    sys.path.append(agent_dir)
import agent as agent_module  # type: ignore
agent_module = importlib.reload(agent_module)
SimpleAgent = agent_module.SimpleAgent

st.set_page_config(page_title="RAG+MCP Agent", layout="wide")

st.title("ü§ñ Retrieval-Aware Tool-Using Agent with MCP")
st.markdown("Query the agent and watch it retrieve context and invoke tools")

# Sidebar: configuration
with st.sidebar:
    st.header("üîå MCP Services")
    st.success("üé® plot-service: port 8000")
    st.success("üî¢ calculator: port 8001")
    st.success("üìÑ pdf-parser: port 8002")
    st.markdown("---")
    
    # LLM mode toggle
    st.header("ü§ñ Agent Mode")
    use_llm = st.checkbox(
        "Use LLM for tool selection",
        value=True,  # Default to LLM mode
        help="Enable to use LLM for intelligent tool selection instead of keywords"
    )
    
    llm_model = "local"
    llm_api_key = ""
    
    if use_llm:
        llm_model = st.radio(
            "LLM Provider",
            options=["local", "openai"],
            index=0,
            help="Local: Free HuggingFace model (~2GB), OpenAI: Paid API"
        )
        
        if llm_model == "local":
            st.info("üÜì Using local TinyLlama model (free, ~2GB download on first use)")
            st.caption("First run will download the model - this may take a few minutes")
        else:
            llm_api_key = st.text_input(
                "OpenAI API Key",
                type="password",
                value=os.getenv('OPENAI_API_KEY', ''),
                help="Required for OpenAI API"
            )
            if llm_api_key:
                st.success("‚úÖ OpenAI mode enabled")
            else:
                st.warning("‚ö†Ô∏è API key required for OpenAI mode")
    else:
        st.info("üìù Using keyword-based tool selection (fast & free)")

# Initialize agent with default endpoints
endpoints = {
    "plot": os.getenv('PLOT_SERVICE_URL', 'http://127.0.0.1:8000/mcp/plot'),
    "calculator": os.getenv('CALCULATOR_URL', 'http://127.0.0.1:8001/mcp/calculate'),
    "pdf": os.getenv('PDF_PARSER_URL', 'http://127.0.0.1:8002/mcp/parse')
}
agent = SimpleAgent(
    endpoints, 
    use_llm=use_llm, 
    llm_model=llm_model if use_llm else "local",
    llm_api_key=llm_api_key if (use_llm and llm_model == "openai") else None
)

# Query input
query = st.text_input("Enter your query:", placeholder="e.g., 'Show me a plot of data'")

if st.button("Execute Query") and query:
    with st.spinner("Processing..."):
        try:
            # Execute agent
            result = agent.plan_and_execute(query)
            
            # Display results
            st.success("Query executed successfully!")
            
            # Show plan
            st.subheader("üìã Agent Plan")
            st.info(result['plan'])
            
            # Show tool result if available
            if result['tool_result']:
                st.subheader("üîß Tool Result")
                tool_result = result['tool_result']
                
                st.json({"status": tool_result.get('status'), "logs": tool_result.get('logs')})
                
                # Display image if present
                if 'result' in tool_result and 'artifact_base64' in tool_result['result']:
                    st.subheader("üìä Generated Plot")
                    img_data = base64.b64decode(tool_result['result']['artifact_base64'])
                    img = Image.open(BytesIO(img_data))
                    st.image(img, caption="Generated by plot-service", use_column_width=True)
            else:
                st.info("No tool was invoked for this query")
                
        except Exception as e:
            st.error(f"Error: {str(e)}")

# Sidebar with info
with st.sidebar:
    st.header("‚ÑπÔ∏è About")
    st.markdown("""
    This demo showcases:
    - **RAG**: Retrieval-Augmented Generation
    - **MCP**: Model Context Protocol tools
    - **Agent**: Autonomous decision-making
    
    The agent:
    1. Retrieves relevant documents
    2. Decides if a tool is needed
    3. Calls MCP endpoints
    4. Returns results
    """)
    
    st.header("üõ†Ô∏è Available Tools")
    st.markdown("""
    - **plot-service** (port 8000): Generate visualizations
    - **calculator** (port 8001): Evaluate math expressions
    - **pdf-parser** (port 8002): Extract text from PDFs
    """)
